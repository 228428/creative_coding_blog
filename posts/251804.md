---
title: Week Seven
published_at: 2025-04-07
snippet: What I learnt in week 7
disable_html_sanitization: true
allow_math: true
---

# Week 7 Session 1

## Reflection

In this session, we started working with sound in our code, which was something completely new to me. One of the most interesting things we learned was that even though sound frequencies increase exponentially, we hear them as if they’re increasing linearly. That made me think about how much of digital media relies on perception, not just raw data. We also learned that to get sound to play in a browser, there needs to be a user gesture like a mouse click before anything can start. At first, I didn’t understand why, but it actually made sense once I realized it's about giving the user control over when sound begins. It also made sound feel more interactive and intentional, rather than just something playing in the background. Overall, this session helped me see sound as something more than just an add-on it’s part of how the experience is shaped and how the system responds.

## HomeWork

For the sound in my AT2 project, I wanted it to feel a bit chaotic but not in a random or messy way. I started playing around with a basic oscillator in p5.js, and honestly, I found it way more interesting than I expected. Just changing the frequency slightly made the whole thing feel alive. I didn’t want the sound to be musical or melodic, but also not just noise. I was trying to find that in-between space something that reacts to the system and shifts over time, but still holds together. I think that’s what effective complexity is all about: it’s not total order or total disorder, but a weird balance of both. When it comes to sound, we usually rely on things like rhythm or repetition to make sense of what we’re hearing, so I played with that idea letting the sound grow or distort as the visual piece changes. I decided not to use voice because I didn’t want it to feel like it was telling you something directly. I liked the idea that the sound is just part of the system more like a mood than a message. Loveless talks about defamiliarisation — making something feel strange or unfamiliar and I tried to do that here. The sound isn’t meant to comfort you or guide you. It’s meant to feel a little off, like you’re listening to something that’s alive, but you can’t quite place what it is.

### Interactive Sound Design: Sinusoidal Chaos Loop (24 Seconds)

For this experiment, I used my teacher’s provided canvas-based Web Audio API sketch as a starting point and played around with it to explore how interactive sound can move in and out of chaos. The goal was to create a system that cycles into disorder and back every 24 seconds, using a sinusoidal control to shape the user experience.

One of the most interesting parts of the experiment was noticing how chaos doesn’t have to be loud or random it can come from subtle changes in rhythm and timing. I explored this by manipulating how fast the notes play, how long they last, and how it all responds to mouse movement (user gesture).

<div style="padding: 2rem; background: #ffe4c4; text-align: center;">
  <p>🎵 Click the canvas to trigger sound. Move your mouse for playback variation.</p>
  <canvas id="vibraphone_canvas" width="400" height="200" style="background: #ff7f50; cursor: pointer;"></canvas>
</div>

<script>
const canvas = document.getElementById('vibraphone_canvas');
const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
let vibraphoneBuffer = null;
let startTime = Date.now();

// Load .wav file
fetch('vibraphone_note.mp3')
  .then(res => res.arrayBuffer())
  .then(data => audioCtx.decodeAudioData(data))
  .then(buffer => {
    vibraphoneBuffer = buffer;
    console.log("✅ Audio loaded!");
  })
  .catch(err => {
    console.error("❌ Error loading audio:", err);
  });

// On canvas click
canvas.onclick = (e) => {
  if (audioCtx.state === 'suspended') {
    audioCtx.resume();
    return;
  }

  if (!vibraphoneBuffer) {
    alert("Audio is still loading...");
    return;
  }

  const x = e.offsetX / canvas.width;

  // 24-second sinusoidal chaos modulation
  let t = (Date.now() - startTime) / 1000;
  let sineMod = Math.sin((2 * Math.PI * t) / 24);
  let chaosFactor = 0.5 + 1.5 * (0.5 + sineMod / 2);
  let rate = (2 ** x) * chaosFactor;

  playVibraphone(rate);
};

function playVibraphone(rate) {
  const source = audioCtx.createBufferSource();
  source.buffer = vibraphoneBuffer;
  source.playbackRate.value = rate;
  source.connect(audioCtx.destination);
  source.start();
}
</script>

# Week 7 Session 2

## Reflection

## HomWork
